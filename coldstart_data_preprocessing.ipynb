{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/f9fRTERvotiufNI9DU+1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ104DUWnuBV",
        "outputId": "7fe51ed0-fcfe-4c11-f206-34a238b7cffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.45.2 datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# Your Python code here\n",
        "!pip install transformers accelerate peft bitsandbytes datasets torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJZXg7ySn0Qj",
        "outputId": "09d77158-92dc-43c4-a523-ff76aac5f25a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coldstart_path = input(\"Enter the full path where the coldstart data should be saved (e.g., mydrive/coldstart_data): \")\n",
        "os.environ[\"COLDSTART_FOLDER_PATH\"] = coldstart_path\n",
        "coldstart_file_path = os.getenv(\"COLDSTART_FOLDER_PATH\") #  Coldstart file path ffor initial train data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSQQ45bUoLyV",
        "outputId": "c2f778fc-25f5-480b-ab6a-f6f14065540c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the full path where the coldstart data should be saved (e.g., mydrive/coldstart_data): /content/drive/MyDrive/Data Projects/DeepSeek project/coldstart_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict, load_dataset, Dataset\n",
        "\n",
        "# Define file paths based on the coldstart_file_path\n",
        "train_file = os.path.join(coldstart_file_path, \"train.jsonl\")\n",
        "valid_file = os.path.join(coldstart_file_path, \"valid.jsonl\")\n",
        "test_file = os.path.join(coldstart_file_path, \"test.jsonl\")\n",
        "\n",
        "# checking the dataset format\n",
        "with open(train_file, \"r\", encoding=\"utf-8\") as file:\n",
        "    for i in range(5):  # Read first 5 lines\n",
        "        print(file.readline().strip())  # Print each line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54mL9qzLoU7U",
        "outputId": "58d4932f-0db4-46a7-d7b0-e1355e1b6715"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"text\": \"<|im_start|>user\\nWhat is the Fibonacci sequence?<|im_end|>\\n<|im_start|>assistant\\nA series where each number is the sum of the two preceding ones, typically starting with 0 and 1.<|im_end|>\"}\n",
            "{\"text\": \"<|im_start|>user\\nIf a car travels 60 miles in 2 hours, what is its average speed?<|im_end|>\\n<|im_start|>assistant\\n<think>Average speed is distance divided by time: 60 miles ÷ 2 hours = 30 miles per hour.</think>\\n<answer>30 miles per hour.</answer><|im_end|>\"}\n",
            "{\"text\": \"<|im_start|>user\\nFor the arithmetic problem 41 - 14 * 5, what's the answer?<|im_end|>\\n<|im_start|>assistant\\n<think> \\nProblem: For the arithmetic problem 41 - 14 * 5, what's the answer?  \\n\\nReasoning:  \\n\\n1. Begin by recognizing that this is a problem involving order of operations (PEMDAS), where multiplication should be performed before subtraction.\\n   \\n2. Perform the multiplication operation first:\\n   14 * 5 = 70\\n\\n3. Now, rewrite the original expression with this result:\\n   41 - 70\\n\\n4. Next, carry out the subtraction:\\n   41 - 70 = -29\\n\\n5. Recheck calculations for accuracy. No discrepancies found.\\n\\n6. Conclude with the final result based on above steps.\\n\\n<answer>The answer is -29</answer>\\n<verifier_answer>-29</verifier_answer>\\n</think><|im_end|>\"}\n",
            "{\"text\": \"<|im_start|>user\\nResolve 71 + 56 and note the result.<|im_end|>\\n<|im_start|>assistant\\n<think>\\nProblem: Resolve 71 + 56 and note the result.  \\nReasoning:  \\n\\n1. Start with the expression: 71 + 56.\\n2. Add the ones place: 1 (from 71) + 6 (from 56) = 7. Write down 7, carry over 1 to the tens place.\\n3. Add the tens place: 7 (carried over) + 5 (from 56) + 7 (from 71) = 19. Write down 9, carry over 1 to the hundreds place.\\n4. Add the hundreds place: 1 (carried over) + 0 (from 71) + 5 (from 56) = 6.\\n5. Combine all results from each step: 6, 9, and 7. The final answer is 697.\\n\\nRecheck the steps, and confirm no discrepancy exists in the calculation.\\n</think>\\n<answer>The result of 71 + 56 is 697.</answer>\\n<verifier_answer>697</verifier_answer><|im_end|>\"}\n",
            "{\"text\": \"<|im_start|>user\\nWhy do we wear seat belts in cars?<|im_end|>\\n<|im_start|>assistant\\nSeat belts keep us in place during sudden stops or collisions, significantly reducing injury risk.<|im_end|>\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the dataset format\n",
        "with open(valid_file, \"r\", encoding=\"utf-8\") as file:\n",
        "    for i in range(5):  # Read first 5 lines\n",
        "        print(file.readline().strip())  # Print each line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F82EO-4_vePS",
        "outputId": "0a120293-27ed-4017-e51c-80ae7eb7b69a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"text\": \"<|im_start|>user\\nHi, how are you?<|im_end|>\\n<|im_start|>assistant\\nHello! I\\u2019m doing well, thanks for asking. How can I help you today?<|im_end|>\"}\n",
            "{\"text\": \"<|im_start|>user\\nWrite a poem about the forest.<|im_end|>\\n<|im_start|>assistant\\nThe forest whispers in emerald hues,\\nA secret realm beneath morning dews,\\nSunlit leaves and hidden streams,\\nA timeless world of waking dreams.<|im_end|>\"}\n",
            "{\"text\": \"<|im_start|>user\\nWhat\\u2019s the capital of Germany?<|im_end|>\\n<|im_start|>assistant\\nThe capital of Germany is Berlin.<|im_end|>\"}\n",
            "{\"text\": \"<|im_start|>user\\nSuggest a good self-improvement book.<|im_end|>\\n<|im_start|>assistant\\nYou might enjoy \\\"Atomic Habits\\\" by James Clear\\u2014great for building and breaking habits effectively.<|im_end|>\"}\n",
            "{\"text\": \"<|im_start|>user\\nHow do I boil an egg perfectly?<|im_end|>\\n<|im_start|>assistant\\nPlace eggs in cold water, bring to a rolling boil, then turn off the heat and cover. After 8\\u201310 minutes, transfer them to ice water for an easier peel.<|im_end|>\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the dataset format\n",
        "with open(test_file, \"r\", encoding=\"utf-8\") as file:\n",
        "    for i in range(5):  # Read first 5 lines\n",
        "        print(file.readline().strip())  # Print each line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INvgytK_vgqR",
        "outputId": "85230217-00b7-4ea6-8ee0-9ae30184b206"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"text\": \"<|im_start|>user\\nTranslate this sentence into French: 'I enjoy learning new skills.'<|im_end|>\\n<|im_start|>assistant\\nJ\\u2019aime apprendre de nouvelles comp\\u00e9tences.<|im_end|>\"}\n",
            "{\"text\": \"<|im_start|>user\\nGive me a random historical fact.<|im_end|>\\n<|im_start|>assistant\\nThe Great Wall of China isn\\u2019t a single continuous wall, but a series of fortifications built over centuries.<|im_end|>\"}\n",
            "{\"text\": \"<|im_start|>user\\nTell me a joke about cats.<|im_end|>\\n<|im_start|>assistant\\nSure. Why did the cat join the Red Cross? Because it wanted to be a first-aid kit-ten!<|im_end|>\"}\n",
            "{\"text\": \"<|im_start|>user\\nWhat is the best way to cook a steak?<|im_end|>\\n<|im_start|>assistant\\nFor a perfect medium-rare steak, sear in a hot pan for 30 seconds on each side, then bake in a 400°F oven for 2 minutes.<|im_end|>\"}\n",
            "{\"text\": \"<|im_start|>user\\nWhat is the most popular sport in Japan?<|im_end|>\\n<|im_start|>assistant\\nBaseball is the most popular sport in Japan, followed by soccer and sumo wrestling.<|im_end|>\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Function to load JSONL file into a Hugging Face dataset\n",
        "def load_jsonl_as_dataset(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = [json.loads(line.strip()) for line in file]  # Load all lines efficiently\n",
        "    return Dataset.from_list(data)\n"
      ],
      "metadata": {
        "id": "opqYr9HWpIWj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = load_jsonl_as_dataset(train_file)\n",
        "dataset_valid = load_jsonl_as_dataset(valid_file)\n",
        "dataset_test = load_jsonl_as_dataset(test_file)"
      ],
      "metadata": {
        "id": "i3KxiA8_H2aG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print dataset structure\n",
        "print(dataset_train, \"\\n\", dataset_valid, \"\\n\", dataset_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_6Di6erpWkD",
        "outputId": "e2f2ed48-9f7e-40e8-b053-e0f2f92b324f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 382\n",
            "}) \n",
            " Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 14\n",
            "}) \n",
            " Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 26\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataset_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "-FWP0W2iplUm",
        "outputId": "79b992fa-cfac-4d2d-9a3e-b4203d544d4b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>datasets.arrow_dataset.Dataset</b><br/>def __init__(arrow_table: Table, info: Optional[DatasetInfo]=None, split: Optional[NamedSplit]=None, indices_table: Optional[Table]=None, fingerprint: Optional[str]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py</a>A Dataset backed by an Arrow table.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 631);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_valid[\"text\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibgikF2ypmg2",
        "outputId": "a316483a-a744-4d5a-bd6e-a836dfc5d4f7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>user\n",
            "Hi, how are you?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Hello! I’m doing well, thanks for asking. How can I help you today?<|im_end|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_qa_from_message(message):\n",
        "    \"\"\"\n",
        "    Extracts the user question and assistant answer from a given message.\n",
        "    \"\"\"\n",
        "    # Regex pattern to match <|im_start|>user and <|im_start|>assistant segments\n",
        "    user_pattern = r\"<\\|im_start\\|>user\\s*(.*?)<\\|im_end\\|>\"\n",
        "    assistant_pattern = r\"<\\|im_start\\|>assistant\\s*(.*?)<\\|im_end\\|>\"\n",
        "\n",
        "    # Extract question and answer using regex\n",
        "    user_match = re.search(user_pattern, message, re.DOTALL)\n",
        "    assistant_match = re.search(assistant_pattern, message, re.DOTALL)\n",
        "\n",
        "    # Get extracted text or None\n",
        "    question = user_match.group(1).strip() if user_match else None\n",
        "    answer = assistant_match.group(1).strip() if assistant_match else None\n",
        "\n",
        "    return question, answer\n",
        "\n",
        "def create_qa_dataset(messages):\n",
        "    \"\"\"\n",
        "    Processes a list of messages and creates a dataset with 'question' and 'answer' columns.\n",
        "    \"\"\"\n",
        "    questions, answers = [], []\n",
        "\n",
        "    for message in messages:\n",
        "        question, answer = extract_qa_from_message(message)\n",
        "        if question and answer:  # Ensure both exist\n",
        "            questions.append(question)\n",
        "            answers.append(answer)\n",
        "\n",
        "    # Convert to Hugging Face Dataset format\n",
        "    dataset = Dataset.from_dict({\"question\": questions, \"answer\": answers})\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "0FdxWK4zprnA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for creating dataset with question and answer columns\n",
        "\n",
        "def process_messages_to_qa_dataset(messages):\n",
        "    \"\"\"\n",
        "    Extracts questions and answers from a list of messages and returns a structured dataset.\n",
        "    \"\"\"\n",
        "    questions, answers = [], []\n",
        "\n",
        "    for message in messages:\n",
        "        # Regex patterns to extract user and assistant messages\n",
        "        user_match = re.search(r\"<\\|im_start\\|>user\\s*(.*?)<\\|im_end\\|>\", message, re.DOTALL)\n",
        "        assistant_match = re.search(r\"<\\|im_start\\|>assistant\\s*(.*?)<\\|im_end\\|>\", message, re.DOTALL)\n",
        "\n",
        "        # Extracted content\n",
        "        question = user_match.group(1).strip() if user_match else None\n",
        "        answer = assistant_match.group(1).strip() if assistant_match else None\n",
        "\n",
        "        if question and answer:  # Ensure valid Q&A pairs\n",
        "            questions.append(question)\n",
        "            answers.append(answer)\n",
        "\n",
        "    # Convert extracted data to a Hugging Face Dataset\n",
        "    return Dataset.from_dict({\"question\": questions, \"answer\": answers})\n"
      ],
      "metadata": {
        "id": "dTEl5Txhpx8y"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_dataset_train = process_messages_to_qa_dataset(dataset_train[\"text\"])\n",
        "qa_dataset_valid = process_messages_to_qa_dataset(dataset_valid[\"text\"])\n",
        "qa_dataset_test = process_messages_to_qa_dataset(dataset_test[\"text\"])"
      ],
      "metadata": {
        "id": "e1h6H-0Op7hQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(qa_dataset_train.column_names)\n",
        "print(qa_dataset_train[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KElysbnQp_dz",
        "outputId": "614875d9-2e5a-4770-d1f4-932507aa4d5d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['question', 'answer']\n",
            "{'question': 'If a car travels 60 miles in 2 hours, what is its average speed?', 'answer': '<think>Average speed is distance divided by time: 60 miles ÷ 2 hours = 30 miles per hour.</think>\\n<answer>30 miles per hour.</answer>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the save path\n",
        "save_path = \"/content/drive/MyDrive/Data Projects/DeepSeek project/coldstart_dataset_csv/\"\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Convert to DataFrame and save\n",
        "pd.DataFrame(qa_dataset_train).to_csv(save_path + \"coldstart_dataset_train.csv\", index=False)\n",
        "pd.DataFrame(qa_dataset_valid).to_csv(save_path + \"coldstart_dataset_valid.csv\", index=False)\n",
        "pd.DataFrame(qa_dataset_test).to_csv(save_path + \"coldstart_dataset_test.csv\", index=False)\n",
        "\n",
        "print(f\"Datasets saved to {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E0ajnkkLLOU",
        "outputId": "a5accbef-aeb9-426d-83a7-67c67bd9f958"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets saved to /content/drive/MyDrive/Data Projects/DeepSeek project/coldstart_dataset_csv/\n"
          ]
        }
      ]
    }
  ]
}